{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: \n",
    "* Student pace: self paced / part time / full time\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: \n",
    "* Blog post URL:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible questions\n",
    "\n",
    "Does area income effect price of houses\n",
    "\n",
    "Does grade have an effect on housing price\n",
    "\n",
    "Does property size effect housing price\n",
    "\n",
    "Does Age of property effect price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find lat and long of city center then subtract out lat and long form it to find the difference \n",
    "# weak correlation to test in model Floor waterfront view and grade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "import math\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.stats.diagnostic import het_white\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.stats.stattools import durbin_watson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/kc_house_data_no_miss_values.csv\")\n",
    "df =df.drop([\"Unnamed: 0\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possibly drop\n",
    "\n",
    "br : sqft liv\n",
    "\n",
    "sqft liv 15 : sqft liv\n",
    "\n",
    "sqft above : sqft liv\n",
    "\n",
    "sqft lot 15 : sqft lot\n",
    "\n",
    "\n",
    "\n",
    "Keep sqft_living, drop sqft_above, sqft_living15 due to high collinearity \n",
    "\n",
    "Keep sqft_lot drop sqft_lot15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = df.drop([\"sqft_above\", \"sqft_living15\", \"sqft_lot15\", \"lat\", \"long\" ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the above table shows that there is a high collinearity between bedrooms and sqft_living, we believe that the number of bedrooms will play a key role in the price of the home, will revisit after modeling to verify if we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"price\", axis=1)\n",
    "y= df[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(df.columns)//3, 3, figsize=(12, 48))\n",
    "\n",
    "i = 0\n",
    "for triaxis in axes:\n",
    "    for axis in triaxis:\n",
    "        df.hist(column = df.columns[i], bins = 100, ax=axis)\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.apply(lambda x: np.log(x).diff(1), axis='rows')\n",
    "with np.errstate(invalid='ignore'):\n",
    "print(df_log)\n",
    "#RuntimeWarning: invalid value encountered in log\n",
    "  #result = getattr(ufunc, method)(*inputs, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = pd.DataFrame()\n",
    "df_log['price'] = df['price'].map(lambda x: np.log(x))\n",
    "df_log['bedrooms'] = df['bedrooms'].map(lambda x: np.log(x))\n",
    "df_log['bathrooms'] = df['bathrooms'].map(lambda x: np.log(x+1))\n",
    "df_log['sqft_living'] = df['sqft_living'].map(lambda x: np.log(x))\n",
    "df_log['sqft_lot'] = df['sqft_lot'].map(lambda x: np.log(x))\n",
    "df_log['floors'] = df['floors'].map(lambda x: np.log(x))\n",
    "#df_log['waterfront'] = df['waterfront'].map(lambda x: np.log(x)): \n",
    "#<ipython-input-19-3d82fac611a8>:8: RuntimeWarning: divide by zero encountered in log\n",
    "df_log['view'] = df['view'].map(lambda x: np.log(x))\n",
    "df_log['condition'] = df['condition'].map(lambda x: np.log(x))\n",
    "df_log['graden'] = df['grade'].map(lambda x: np.log(x))\n",
    "df_log['sqft_above'] = df['sqft_above'].map(lambda x: np.log(x))\n",
    "df_log['sqft_basement'] = df['sqft_basement'].map(lambda x: np.log(x))\n",
    "df_log['yr_built'] = df['yr_built'].map(lambda x: np.log(x))\n",
    "df_log['yr_renovated'] = df['yr_renovated'].map(lambda x: np.log(x))\n",
    "df_log['zipcode'] = df['zipcode'].map(lambda x: np.log(x))\n",
    "df_log['lat'] = df['lat'].map(lambda x: np.log(x))\n",
    "df_log['long'] = df['long'].map(lambda x: np.log(x))\n",
    "df_log['sqft_living15'] = df['sqft_living15'].map(lambda x: np.log(x))\n",
    "df_log['sqft_lot15'] = df['sqft_lot15'].map(lambda x: np.log(x))\n",
    "df_log['Income'] = df['Income'].map(lambda x: np.log(x))\n",
    "df_log['house_age'] = df['house_age'].map(lambda x: np.log(x))\n",
    "df_log['year_sold'] = df['year_sold'].map(lambda x: np.log(x))\n",
    "df_log['season'] = df['season'].map(lambda x: np.log(x)).map(lambda x: np.log(x))\n",
    "df_log['renovated'] = df['renovated'].map(lambda x: np.log(x))\n",
    "\n",
    "df_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_log = pd.DataFrame()\n",
    "df_log['price'] = df['price'].map(lambda x: np.log(x))\n",
    "\n",
    "df_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(df.columns)//3, 3, figsize=(12, 48))\n",
    "\n",
    "i = 0\n",
    "for triaxis in axes:\n",
    "    for axis in triaxis:\n",
    "        df.hist(column = df_log.columns[i], bins = 100, ax=axis)\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(df_log)\n",
    "scaled_df = pd.DataFrame(scaled)\n",
    "column_dict = dict(zip(scaled_df.columns, df_log.columns))\n",
    "\n",
    "scaled_df.rename(columns=column_dict, inplace=True)\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'price'\n",
    "predictors_scaled = scaled_df.drop(['price'], axis=1)\n",
    "pred_scaled_sum = '+'.join(predictors_scaled.columns)\n",
    "formula_scaled = outcome + '~' + pred_scaled_sum\n",
    "\n",
    "model = ols(formula = formula_scaled, data=scaled_df).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importances are based on coefficient magnitude, so\n",
    "# we need to scale the data to normalize the coefficients\n",
    "X_train_for_RFECV = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "model_for_RFECV = LinearRegression()\n",
    "\n",
    "# Instantiate and fit the selector\n",
    "selector = RFECV(model_for_RFECV, min_features_to_select=10 ,cv=splitter)\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# Print the results\n",
    "print(\"Was the column selected?\")\n",
    "for index, col in enumerate(X_train.columns):\n",
    "    print(f\"{col}: {selector.support_[index]}\")\n",
    "####updated # of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train = df.drop(\"price\", axis=1)\n",
    "y_train = df[\"price\"]\n",
    "\n",
    "X_test = df.drop(\"price\", axis=1)\n",
    "y_test = df[\"price\"]\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = LinearRegression()\n",
    "\n",
    "splitter = ShuffleSplit(n_splits=3, test_size=0.25, random_state=0)\n",
    "\n",
    "baseline_scores = cross_validate(\n",
    "    estimator=baseline_model,\n",
    "    X=X_train[[\"sqft_living\"]],\n",
    "    y=y_train,\n",
    "    return_train_score=True,\n",
    "    cv=splitter\n",
    ")\n",
    "\n",
    "print(\"Train score:     \", baseline_scores[\"train_score\"].mean())\n",
    "print(\"Validation score:\", baseline_scores[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numerical = df[['price', 'bedrooms','bathrooms', 'sqft_living', 'floors', 'sqft_lot', 'sqft_basement', 'sqft_living15', 'sqft_lot15','Income',]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numerical1 = df[['price', 'bedrooms','bathrooms', 'sqft_living', 'floors', 'sqft_lot', 'sqft_basement', 'Income',]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(df_numerical.values, i) for i in range(df_numerical.shape[1])]\n",
    "vif[\"features\"] = df_numerical.columns\n",
    "vif.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"price\"]\n",
    "X = df.drop(\"price\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y, sm.add_constant(X), missing = \"drop\").fit()\n",
    "results = model.summary()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformation = preprocessing.StandardScaler()\n",
    "data = data_transformation.fit_transform(X_train)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = df2[:, 0]\n",
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df2[:,1:]\n",
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train1.shape)\n",
    "print(X_test1.shape)\n",
    "print(y_train1.shape)\n",
    "print(y_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformation = preprocessing.StandardScaler()\n",
    "data = data_transformation.fit_transform(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(data, y_train1)\n",
    "print(model.intercept_)\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.score(data, y_train1)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = model.score(data_transformation.transform((X_test1)), y_test1)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(data_transformation.transform(X_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test1, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test1, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test1, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = pd.DataFrame({'Actual value': y_test1, 'Predicted value': y_pred, \"Difference\" : (y_test1-y_pred).round(2)})\n",
    "model1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1[\"Difference\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = np.square(np.subtract(y_test1,y_pred)).mean() \n",
    " \n",
    "RMSE = math.sqrt(MSE)\n",
    "RMSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting 3 different polynomial regression models from degree 2 to degree 4\n",
    "for index, degree in enumerate([2, 3, 4]):\n",
    "    \n",
    "    # Instantiate PolynomialFeatures\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    \n",
    "    # Fit and transform X_train\n",
    "    X_poly_train = poly.fit_transform(X_train)\n",
    "    \n",
    "    # Instantiate and fit a linear regression model to the polynomial transformed train features\n",
    "    reg_poly = LinearRegression().fit(X_poly_train, y_train)\n",
    "    \n",
    "    # Transform the test data into polynomial features\n",
    "    X_poly_test = poly.transform(X_test)\n",
    "    \n",
    "    # Get predicted values for transformed polynomial test data  \n",
    "    y_pred = reg_poly.predict(X_poly_test)\n",
    "    \n",
    "    # Evaluate model performance on test data\n",
    "    print(\"degree %d\" % degree, r2_score(y_test, y_pred))\n",
    "    \n",
    "    # Transform the full data\n",
    "    X_poly = poly.transform(X)\n",
    "    \n",
    "    # Now, we want to see what the model predicts for the entire data  \n",
    "    y_poly = reg_poly.predict(X_poly)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y-y_pred\n",
    "plt.plot(X,residuals, 'o', color='darkblue')\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.xlabel(\"Independent Variable\")\n",
    "plt.ylabel(\"Residual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residuals skewed to the left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumption of Independent Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid = model1.resid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_errors = durbin_watson(model.resid)\n",
    "ind_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the statistical value of 2.01, the test provides evidence that there is no serial correlation present meaning the residual error terms are uncorrelated and are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumption of Normality of the Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['Jarque-Bera', 'Chi^2 two-tail prob.', 'Skew', 'Kurtosis']\n",
    "test = stats.jarque_bera(model.resid)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test is significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running Q-Q Plot\n",
    "stats.probplot(model.resid, dist=\"norm\", plot= plt)\n",
    "plt.title(\"Model1 Residuals Q-Q Plot\")\n",
    "\n",
    "plt.savefig(\"Model1_Resid_qqplot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Homoscedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_test = het_white(resid, model.model.exog)\n",
    "bp_test = het_breuschpagan(resid, model.model.exog)\n",
    "\n",
    "labels = ['LM Statistic', 'LM-Test p-value', 'F-Statistic', 'F-Test p-value']\n",
    "print(dict(zip(labels, bp_test)))\n",
    "print(dict(zip(labels, white_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "def normality_of_residuals_test(model):\n",
    "    '''\n",
    "    Function for drawing the normal QQ-plot of the residuals and running 4 statistical tests to \n",
    "    investigate the normality of residuals.\n",
    "    \n",
    "    Arg:\n",
    "    * model - fitted OLS models from statsmodels\n",
    "    '''\n",
    "    sm.ProbPlot(model.resid).qqplot(line='s');\n",
    "    plt.title('Q-Q plot');\n",
    "\n",
    "    jb = stats.jarque_bera(model.resid)\n",
    "    sw = stats.shapiro(model.resid)\n",
    "    ad = stats.anderson(model.resid, dist='norm')\n",
    "    ks = stats.kstest(model.resid, 'norm')\n",
    "    \n",
    "    print(f'Jarque-Bera test ---- statistic: {jb[0]:.4f}, p-value: {jb[1]}')\n",
    "    print(f'Shapiro-Wilk test ---- statistic: {sw[0]:.4f}, p-value: {sw[1]:.4f}')\n",
    "    print(f'Kolmogorov-Smirnov test ---- statistic: {ks.statistic:.4f}, p-value: {ks.pvalue:.4f}')\n",
    "    print(f'Anderson-Darling test ---- statistic: {ad.statistic:.4f}, 5% critical value: {ad.critical_values[2]:.4f}')\n",
    "    print('If the returned AD statistic is larger than the critical value, then for the 5% significance level, the null hypothesis that the data come from the Normal distribution should be rejected. ')\n",
    "    \n",
    "normality_of_residuals_test(lin_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
